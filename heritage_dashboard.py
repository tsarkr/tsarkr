# -*- coding: utf-8 -*-
import pandas as pd
import streamlit as st
import pymysql
from sqlalchemy import create_engine
import configparser
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

DB = st.secrets["mysql"]

# âœ… í•œê¸€ í°íŠ¸ ì„¤ì •
font_paths = fm.findSystemFonts(fontext='ttf')
for path in font_paths:
    if 'NanumGothic' in path:
        plt.rcParams['font.family'] = fm.FontProperties(fname=path).get_name()
        break
plt.rcParams['axes.unicode_minus'] = False

# âœ… config.ini ë¡œë“œ
def load_config(path="config.ini"):
    config = configparser.ConfigParser()
    config.read(path)
    return {
        "api_key": config.get("google_api", "api_key"),
        "db_config": {
            "user": config.get("mysql", "user"),
            "password": config.get("mysql", "password"),
            "host": config.get("mysql", "host"),
            "database": config.get("mysql", "database"),
            "charset": config.get("mysql", "charset"),
        }
    }

CONFIG = load_config()
DB = CONFIG["db_config"]

# âœ… DB ì—°ê²°
@st.cache_resource
def get_engine():
    engine = create_engine(
        f"mysql+pymysql://{DB['user']}:{DB['password']}@{DB['host']}/{DB['database']}?charset={DB['charset']}"
    )
    st.success("âœ… DB ì—°ê²° ì„±ê³µ")
    return engine

engine = get_engine()

# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
@st.cache_data(ttl=300)
def load_data():
    videos = pd.read_sql("SELECT * FROM videos", engine)
    comments = pd.read_sql("SELECT * FROM comments", engine)
    st.write("ğŸ“¥ videos ë¡œë”© ì™„ë£Œ:", videos.shape)
    st.write("ğŸ“¥ comments ë¡œë”© ì™„ë£Œ:", comments.shape)
    return videos, comments

videos_df, comments_df = load_data()

# âœ… Streamlit ë ˆì´ì•„ì›ƒ êµ¬ì„±
st.set_page_config(layout="wide", page_title="êµ­ê°€ìœ ì‚° ì½˜í…ì¸  ëŒ€ì‹œë³´ë“œ")
st.title("ğŸ“Š êµ­ê°€ìœ ì‚° ìœ íŠœë¸Œ ì½˜í…ì¸  ìˆ˜ì§‘ ëŒ€ì‹œë³´ë“œ")

# âœ… ë°ì´í„° ë””ë²„ê¹… í™•ì¸
st.subheader("âœ… ë¡œë”©ëœ ë°ì´í„° ìƒíƒœ")
st.write("ì˜ìƒ ë°ì´í„°í”„ë ˆì„ í¬ê¸°:", videos_df.shape)
st.write("ëŒ“ê¸€ ë°ì´í„°í”„ë ˆì„ í¬ê¸°:", comments_df.shape)

if videos_df.empty:
    st.warning("âš ï¸ videos í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
if comments_df.empty:
    st.warning("âš ï¸ comments í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# âœ… ìƒë‹¨ ìš”ì•½ ì§€í‘œ
col1, col2, col3 = st.columns(3)
col1.metric("ğŸï¸ ì´ ì˜ìƒ ìˆ˜", f"{len(videos_df):,} ê°œ")
col2.metric("ğŸ’¬ ì´ ëŒ“ê¸€ ìˆ˜", f"{len(comments_df):,} ê°œ")
col3.metric("ğŸ“º ì±„ë„ ìˆ˜", f"{videos_df['channel_id'].nunique():,} ê°œ")

st.markdown("---")

# âœ… ë‚ ì§œë³„ ìˆ˜ì§‘ ì˜ìƒ ìˆ˜
st.subheader("ğŸ—“ï¸ ìˆ˜ì§‘ ë‚ ì§œë³„ ì˜ìƒ ìˆ˜")
videos_df["crawled_date"] = pd.to_datetime(videos_df["crawled_at"]).dt.date
daily_counts = videos_df.groupby("crawled_date").size()

st.bar_chart(daily_counts)

# âœ… ì¸ê¸° ì˜ìƒ Top 10
st.subheader("ğŸ”¥ ì¡°íšŒìˆ˜ ê¸°ì¤€ ì¸ê¸° ì˜ìƒ Top 10")
top_videos = videos_df.sort_values("view_count", ascending=False).head(10)
st.dataframe(top_videos[["title", "view_count", "like_count", "comment_count", "published_at"]])

# âœ… ìµœê·¼ ëŒ“ê¸€ 100ê±´ ë¯¸ë¦¬ë³´ê¸°
st.subheader("ğŸ“ ìµœê·¼ ìˆ˜ì§‘ëœ ëŒ“ê¸€")
recent_comments = comments_df.sort_values("crawled_at", ascending=False).head(100)
st.dataframe(recent_comments[["video_id", "author_display_name", "text_display", "published_at"]])